---
layout: post
comments: true
categories: Probability
published: true
---

<b>Problem 1:</b> Suppose that you have a biased coin (probability $$ p $$ of getting heads). How can you simulate an unbiased coin?

<b>Problem 2:</b> Conversely, suppose that you have a unbiased coin. Can you simulate a coin with probability p of getting heads?

<b>Problem 3:</b> For each of the above, what is the expected number of coin flips before you get the desired "answer"?

---

<b>Solution 1:</b> Suppose that getting a heads then tails is event A, and getting tails then heads is event B. Then these event are disjoint and equiprobable (since $$ \mathbb{P}(A) = p(p-1) = \mathbb{P}(b) $$ ). Hence I flip the coin twice. If I get event $$ A $$ I call it heads. If I get event $$ B $$ I call it tails. Otherwise I repeat until either $$ A $$ or $$ B $$ happens (which it will in finite time since the number of throws needed follows a Geometric Progression)

---

<b>Solution 2:</b> This one is a bit trickier. Consider an infinite sequence of throws. We will write a number between 0 and 1 expanded in binary. Each digit is decided by a throw, with it being a 0 if tails or 1 if heads. By letting the number of throws go to infinity, we get a uniform distribution $$ X $$ on the unit interval $$ [0,1] $$. Hence we consider the events $$ \{ X \leq p \} $$ and $$ \{ X \geq p \} $$ 